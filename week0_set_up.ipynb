{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYAKVu60ucQqbNz5I5pwBv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Allraindrop/gt-nlp-summarization/blob/main/week0_set_up.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Step 0: Install required packages\n",
        "# ===========================\n",
        "!pip install transformers datasets tqdm pandas\n",
        "\n",
        "# ===========================\n",
        "# Step 1: Load dataset and clean text\n",
        "# ===========================\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Load CNN/DailyMail dataset\n",
        "dataset = load_dataset(\"cnn_dailymail\", '3.0.0')\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    Clean the input text by removing extra whitespaces or unwanted characters.\n",
        "    \"\"\"\n",
        "    return \" \".join(text.split())\n",
        "\n",
        "print(f\"Training set size: {len(dataset['train'])}\")\n",
        "print(f\"Test set size: {len(dataset['test'])}\")\n",
        "\n",
        "# ===========================\n",
        "# Step 2: Initialize summarization pipeline\n",
        "# ===========================\n",
        "from transformers import pipeline\n",
        "\n",
        "# Initialize summarization pipeline using BART large\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "MAX_INPUT_LENGTH = 1024  # BART max tokens\n",
        "\n",
        "# ===========================\n",
        "# Step 3: Generate summaries for batch\n",
        "# ===========================\n",
        "NUM_EXAMPLES = 50  # how many examples to generate (adjustable)\n",
        "results = []\n",
        "\n",
        "for i in tqdm(range(NUM_EXAMPLES), desc=\"Generating summaries\"):\n",
        "    article = clean_text(dataset['train'][i]['article'])\n",
        "    reference_summary = clean_text(dataset['train'][i]['highlights'])\n",
        "\n",
        "    # Generate summary safely\n",
        "    summary = summarizer(\n",
        "        article,\n",
        "        max_length=80,\n",
        "        min_length=30,\n",
        "        do_sample=False,\n",
        "        truncation=True\n",
        "    )\n",
        "    generated_summary = summary[0]['summary_text']\n",
        "\n",
        "    # Append results\n",
        "    results.append({\n",
        "        \"article\": article,\n",
        "        \"generated_summary\": generated_summary,\n",
        "        \"reference_summary\": reference_summary\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame for easier handling\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# ===========================\n",
        "# Step 4: Save results\n",
        "# ===========================\n",
        "# Save to CSV for easy GitHub upload\n",
        "df.to_csv(\"generated_summaries.csv\", index=False, encoding=\"utf-8\")\n",
        "print(\"Summaries saved to generated_summaries.csv\")\n",
        "\n",
        "# ===========================\n",
        "# Step 5: Visualize some examples\n",
        "# ===========================\n",
        "for idx in range(3):  # show first 3 examples\n",
        "    print(f\"--- Example {idx+1} ---\")\n",
        "    print(\"Original Article (first 200 chars):\", df['article'][idx][:200], \"...\")\n",
        "    print(\"Generated Summary:\", df['generated_summary'][idx])\n",
        "    print(\"Reference Summary:\", df['reference_summary'][idx])\n",
        "    print(\"---\\n\")\n",
        "\n",
        "# ===========================\n",
        "# Step 6 (Optional): Push to GitHub\n",
        "# ===========================\n",
        "# Make sure you've connected Colab to your GitHub account\n",
        "# and set up personal access token if needed\n",
        "# Uncomment below if you want to push automatically\n",
        "\n",
        "# !git config --global user.email \"your_email@example.com\"\n",
        "# !git config --global user.name \"YourName\"\n",
        "# !git init\n",
        "# !git add generated_summaries.csv\n",
        "# !git commit -m \"Add generated summaries\"\n",
        "# !git branch -M main\n",
        "# !git remote add origin https://github.com/yourusername/yourrepo.git\n",
        "# !git push -u origin main\n"
      ],
      "metadata": {
        "id": "8NaecEbSxqjo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}